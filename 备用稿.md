# Lightweight and Efficient Spiking Neural Network

## I Introduction

**背景介绍**

**1.介绍SNN和Spiking Transformer**

脉冲神经网络（SNN）将深度学习技术扩展到生物启发的计算领域。由于脉冲信号在生物神经系统中的广泛存在，SNN 已在多个应用领域得到应用，包括视觉处理、语音识别和机器人控制等。SNN 的处理过程通过将连续信号转换为离散的脉冲序列，利用脉冲的时序信息进行信息传递和处理。脉冲神经网络的这种处理方式使其能够更好地模拟生物神经系统的工作方式，从而在某些任务上表现出与人类大脑更相似的特性。

脉冲变压器（Spiking Transformer）是一种基于脉冲神经网络的变压器模型，将变压器架构与脉冲神经网络的计算方式相结合。这种脉冲变压器模型通过利用脉冲神经网络的脉冲信号处理方式来实现自然语言处理任务，如机器翻译等。脉冲变压器利用脉冲编码的信息表示和时序信息传递的优势，将深度学习和生物启发的计算相结合，为处理序列数据带来新的可能性和潜力。

**研究动机**



与传统的Transformer模型不同，Spiking Transformer 结合了脉冲神经网络的特点，输入信息引入了时间维度，为计算和数据移动增加了负担。

输入在多个timestep中接收和处理数据。这不仅需要更多的时间，还限制了架构数据流和可以利用的数据重用



与传统的Transformer模型相比，Spiking Transformer独特地融合了脉冲神经网络的特性，引入了时间维度，使得计算和数据传输的负担显著增加。在多个时间步内接收和处理输入数据，不仅导致了时间效率的降低，同时也限制了架构的数据流动性和潜在的数据重用能力。



计算模式强调脉冲的稀疏性和时序特性。输入数据通常是稀疏且高度不规则的，这使得 Spiking Transformer 在计算时依赖稀疏矩阵乘法（SpMM）。脉冲输入和注意力机制的动态变化引入了独特的负载不平衡和数据局部性挑战，进一步阻碍了其有效处理。

目前还未有专用硬件加速器的方案，以提高 Spiking Transformer 的计算效率。要充分探索 SNN 的时间稀疏性不规则模式带来的挑战。



而目前尚未出现专用的硬件加速器方案来提升 Spiking Transformer 的计算效率，因此，有必要深入探索脉冲神经网络在时间稀疏性和不规则模式下所面临的挑战。



与传统的 Transformer 模型相比，Spiking Transformer 独特地融合了脉冲神经网络的特性，引入了时间维度，这显著增加了计算和数据传输的负担。在多个时间步内接收和处理输入数据，导致了时间效率的降低，同时限制了架构的数据流动性和潜在的数据重用能力。此外，经过编码后的输入数据通常呈现出稀疏且高度不规则的特性，这使得 Spiking Transformer 在计算时依赖于稀疏矩阵乘法（SpMM）。脉冲输入的动态变化引入了独特的负载不平衡和数据局部性挑战，进一步阻碍了其有效处理。



尽管Spiking Transformer的相较于SNN的优秀性能, 但其庞大的权重参数难以部署到资源受限的边缘设备。而现有的一些Transformer硬件加速算法，从模型稀疏化工作入手，通过修建冗余的权重参数来提高硬件性能而不影响准确性（1~2%）。

然而现有的剪枝算法通常采用非结构化方式，虽然极大限度的提高模型的稀疏性（95%），（make it possible） 将模型部署于资源受限的模块中，但这种不规则剪枝算法将引入非0值的不确定性，需要额外的存储开销来应对非0值的随机分布。此外，这种不规则的剪枝技术也给计算带来了新的挑战。在并行计算时，随机剪枝后的稀疏权重被分配到不同 PE中进行矩阵计算，由于非0元素的不确定性，不同PE分配的权重个数不尽相同，不可避免地导致不同PE的工作负载不平衡，从而降低了资源利用率，从而影响并行效率

![image-20241006164001331](C:\Users\10418\AppData\Roaming\Typora\typora-user-images\image-20241006164001331.png)

![image-20241006164021242](C:\Users\10418\AppData\Roaming\Typora\typora-user-images\image-20241006164021242.png)

![image-20241006164006959](C:\Users\10418\AppData\Roaming\Typora\typora-user-images\image-20241006164006959.png)

尽管 Spiking Transformer 相较于传统的脉冲神经网络（SNN）表现出卓越的性能，但其庞大的权重参数使得在资源受限的边缘设备上部署变得困难。目前，一些现有的 Transformer 硬件加速算法通过模型稀疏化来解决这一问题——采用修剪冗余的权重参数以提高硬件性能，同时保持较高的准确性（仅降低 1%~2%）。然而，这种剪枝算法通常采用非结构化方式，虽然能显著提高了模型的稀疏性（可达 95%）并大幅度降低模型的浮点计算量（FLOPs），使得模型能够部署在资源受限的模块中。但在实际计算中，这种不规则剪枝导致了非零权重在空间上分布的不确定性，因此需要引入额外的存储和寻址开销来应对这一随机分布。此外，非结构化的剪枝技术还给计算带来了新的挑战。在并行计算中，随机剪枝后的稀疏权重被分配到不同的处理单元（PE）进行矩阵计算。由于非零元素的分布不确定性，不同 PE 分配的非0权重密度各异，不可避免地导致了整体工作的负载不平衡，从而降低了资源利用率并影响了并行效率。



然而，与现有的Transformer加速器相比，有关于Spiking Transformer的的研究工作要少很多。迄今为止，关于Spiking Transformer的优化主要集中在算法和软件层面，但专用硬件加速器的开发仍然研究不足。目前尚未出现专用的Spiking Transformer硬件加速器，能够充分探索脉冲神经网络在时间和空间上稀疏性和不规则模式下的挑战，以此提升硬件的计算效率。C-Transformer xxx， CICC xxx



为了解决上述提到的困难，本文是充分探索和利用了脉冲神经网络的稀疏性，实现一个轻量和高效的Spiking Transformer硬件加速器。

我们提出了两种关键技术，以实现基于尖峰的计算，同时有效地探索空间和时间上的非结构化发射活动稀疏性。首先，xxxx, 这产生了提出的*并行时间批处理* （PTB） 技术，通过该技术，在数组上同时处理多个时间批处理。其次，xxxx，提出了一个剪枝策略。在xxxx基础上，我们进一步提出了一种*时空不重叠的尖峰活动打包* （StSAP） 技术来识别和组合其尖峰输入在时间或空间上不重叠的时间批次。这项工作提供了一种新颖的解决方案，以解决刻板印象（时间-串行）方法中的限制，以实现高能效数据流和时域并行处理，以实现内存密集型 SNN 加速器。



**2.介绍遇到的问题，软件时间由于T的引入，训练加速，充分利用SNN的稀疏的脉冲活动**

这是因为当今的图形处理单元 （GPU） 缺乏无缝处理二进制、稀疏和时空输入的能力 [11]。多年来，研究人员提出了解决方案，可以在不丢失信息的情况下为更深入的模型训练基于尖峰的 SNN 训练，并产生接近 ANN 准确性的产量。为了处理多位输入，例如在基于传感器的实际应用中的典型输入，输入通常使用速率编码 [16]、时间编码 [17] 或等级序编码 [18] 在时间域中进行尖峰编码。或者，一些研究人员主张直接在第一卷积层中馈送模拟像素值，从而仅在后续层中发射尖峰 [19]。这可以减少实现 SOTA 精度所需的时间步数，但代价是第一层现在需要 MAC [19]，这使得硬件加速变得复杂。

尽管尖峰变压器使用简化的计算，但当部署在CPU和GPU等通用计算平台上时，它们仍然效率低下。这些低效率是由两个因素引起的：首先，尖峰变压器由于频繁访问中间结果的内存而导致大量数据通信开销，随着尖峰编码长度的延长，这种情况会恶化。其次，尖峰变压器利用二进制数据，而通用计算平台使用更高精度的资源运行，导致计算和存储效率低下[17]。虽然尖峰变压器的优化工作迄今为止一直集中在算法和软件级别，但专用硬件加速器的开发仍然研究不足。





尽管 Spiking Transformer 相较于传统的脉冲神经网络（SNN）表现出卓越的性能，但其庞大的权重参数使得在资源受限的边缘设备上部署变得困难。目前，一些现有的 Transformer 硬件加速算法通过模型稀疏化来解决这一问题——采用修剪冗余的权重参数以提高硬件性能，同时保持较高的准确性（仅降低 1%~2%）。然而，这种剪枝算法通常采用非结构化方式，虽然能显著提高了模型的稀疏性（可达 95%）并大幅度降低模型的浮点计算量（FLOPs），使得模型能够部署在资源受限的模块中。但在实际计算中，这种不规则剪枝导致了非零权重在空间上分布的不确定性，因此需要引入额外的存储和寻址开销来应对这一随机分布。此外，非结构化的剪枝技术还给计算带来了新的挑战。在并行计算中，随机剪枝后的稀疏权重被分配到不同的处理单元（PE）进行矩阵计算。由于非零元素的分布不确定性，不同 PE 分配的非0权重密度各异，不可避免地导致了整体工作的负载不平衡，从而降低了资源利用率并影响了并行效率。



为了解决上述提到的困难，本文提出了PruneSpikformer，一个轻量和高效的Spiking Transformer硬件加速器。本文是充分探索和利用了脉冲神经网络的稀疏性，

我们提出了两种关键技术，以实现基于脉冲的计算，同时有效地探索空间和时间上的脉冲的稀疏性 。（1）我们首先引入了一种高效的稀疏编码方式，能够对输入数据进行有效的编码处理，减少冗余的信息传递，只保留数据的重要特征，从而降低计算资源的消耗。（2）基于PE的结构化剪枝算法，能够

**3.介绍现有的算法的缺点（非结构化剪枝算法）**，

**4.跟DNN相比，关于SNN的硬件加速器研究要少很多，现有的硬件加速器的运算缺点（非SNN**）

然而，与现有的Transformer加速器相比，有关于Spiking Transformer的硬件加速器的研究要少很多。C-Transformer

5.介绍本项工作的特点。

在本文中，we wonder ：是否能充分利用脉冲神经网络的稀疏性，实现一个轻量和高效的Spiking Transformer。为此，我们设计了评估了多种稀疏方式，以充分脉冲的潜力与优势，

**贡献概述**

5.我们的贡献总结如下：

* 我们提出了一个名为xxx的Spiking Transformer算法-硬件协同设计的加速器框架，旨在利用脉冲神经网络独特的时空稀疏特性，解决Spiking Transformer的不规则稀疏计算，旨在通过协调算法和硬件级别的创新来提高Spiking Transformer的计算效率。据我们所知，ViTCoD是第一个从时间和空间的角度进行稀疏处理加速的SNN加速器，为高效的类脑计算提供了新的视角。

* 时间层面：Spiking Transformer集成了一个基于脉冲的线性稀疏编码层，使其对输入像素进行脉冲编码，以最大限度的降低输入神经元的脉冲发射率，而不会牺牲准确性，大大减少了主要的脉冲计算，从而降低了整体的能耗。该方案不改变整体的计算流程，能够适配任何网络模型。
* 空间层面：
* 除此之外，我们还进一步集成了一个全局共享的轻量级的自动编码器模块，以实现将主要的高成本数据移动转换为低成本计算。具体来说，为了缓解PE利用率低的问题，ViTCoD的自动编码器模块利用不同注意头之间的Q和K向量具有相似性并且因此可以从高度压缩的表示中恢复的假设，有助于降低计算与通信比。因此，ViTCoD算法能够实现高度稀疏的注意力，同时增强规则和减少的数据访问，将内存/带宽受限的场景推向最优设计





传统，大大减少了占功耗主导地位的数据读取。

此外，传统的非结构化LTH剪枝方式能够 实现极其稀疏的Spiking Transformer，实现将模型部署到有限资源的硬件设备。但权重的高稀疏性不可避免地增加了不规则数据访问和处理的程度，不同的PE分配不同数量的权重数据计算，因此将会导致各个模块严重的工作负载不平衡问题。此外，当处理高度稀疏的权重区域时，效率在很大程度上受到存储器带宽的限制



在硬件层面上，我们适配了输入脉冲稀疏与权重稀疏两种策略的稀疏计算模式，以最大化降低计算功耗，同时集成片上解码器模块，来解压缩模型权重，大大减少数据的存取，利用低成本的计算功耗来降低访存功耗，以提高效率。

![image-20241008232602901](C:\Users\10418\AppData\Roaming\Typora\typora-user-images\image-20241008232602901.png)

![image-20241008232457988](C:\Users\10418\AppData\Roaming\Typora\typora-user-images\image-20241008232457988.png)

![image-20241008232816212](C:\Users\10418\AppData\Roaming\Typora\typora-user-images\image-20241008232816212.png)

![image-20241008232808799](C:\Users\10418\AppData\Roaming\Typora\typora-user-images\image-20241008232808799.png)





idea:此时可以画一张图，例举Spikformer，Spikingformer，SEW-ResNet，spike-driven在cifar10，cifar100，cifar10dvs上的脉冲发射率